{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from datosgobmx import client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pollutant(p):\n",
    "    \"\"\"Function that returns a str with a pollutant.\n",
    "\n",
    "    Args:\n",
    "        p (int): values from 0 to 5 for list place.\n",
    "\n",
    "    Returns:\n",
    "        str: pollutant.\n",
    "    \"\"\"\n",
    "    #Parametros de contaminantes\n",
    "    param = ['CO','NO2', 'O3','PM10','PM25','SO2']\n",
    "    return (param[p])\n",
    "\n",
    "#Funcion para guardar json con informacion de contaminantes a csv\n",
    "def parse_mediciones_json(json_file):\n",
    "    \"\"\"Function that converts json files to csv.\n",
    "\n",
    "    Args:\n",
    "        json_file ([json]): File in json.\n",
    "\n",
    "    Returns:\n",
    "        [csv]: json convedescriptionrted to csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open (json_file,'r') as aux:\n",
    "        results = json.load(aux)['results']\n",
    "        \n",
    "    pre_data=[]\n",
    "\n",
    "    for r in results:\n",
    "        \n",
    "        aux = pd.DataFrame.from_dict(r,orient='index').T\n",
    "        pre_data.append(aux)\n",
    "    \n",
    "    if len(pre_data)>0:\n",
    "        pre_data = pd.concat(pre_data,ignore_index=True)\n",
    "        return (pre_data)\n",
    "\n",
    "\n",
    "def data_gdl(city, num_datos):\n",
    "    \"\"\"Function that downloads csv with from SINAICA for a given city.\n",
    "\n",
    "    \"\"\"\n",
    "    dir_raw = '../data/raw/'\n",
    "\n",
    "    city_dict = {'gdl':'Guadalajara'}\n",
    "\n",
    "    #Checa si existe la carpeta de la ciudad y contaminantes y los crea si no existen\n",
    "    if not os.path.isdir(dir_raw+city): \n",
    "        os.mkdir(dir_raw+city) \n",
    "        for i in range(6): os.mkdir(dir_raw+city+'/'+pollutant(i))\n",
    "\n",
    "\n",
    "    #Itera sobre la lista de contaminantes y obtiene ese parametro para la ciudad establecida\n",
    "    for i in range(6):\n",
    "        filename = city+'_'+pollutant(i)\n",
    "        filename = dir_raw+city+'/'+pollutant(i)+'/'+filename\n",
    "        \n",
    "        data_api = client.makeCall('sinaica',{'pageSize':num_datos, 'city':city_dict[city], 'parametro':pollutant(i)})\n",
    "            \n",
    "        with open (filename,'w') as outfile:\n",
    "            json.dump(data_api,outfile)\n",
    "            \n",
    "        sinaica_mediciones = parse_mediciones_json(filename)\n",
    "        sinaica_mediciones.to_csv(filename+'.csv', index=False)\n",
    "\n",
    "def est_csv():\n",
    "    \"\"\"Downloads csv with information about Mexican air quality stations using SINAICA api\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    parametros_request = client.makeCall('sinaica-estaciones',{'pageSize':200})\n",
    "    dir_raw_grl = '../data/raw/Grl/'\n",
    "\n",
    "    estaciones = []\n",
    "    #Obtiene datos de todas las estaciones para despues iterar sobre ellas\n",
    "    for v in parametros_request['results']:\n",
    "        aux = pd.DataFrame.from_dict(v,orient='index').T\n",
    "        estaciones.append(aux)\n",
    "\n",
    "    estaciones = pd.concat(estaciones, ignore_index=True)\n",
    "\n",
    "    #Quita las estaciones que esten fuera de Mexico\n",
    "    mask = (estaciones.lat.between(14, 34.5)) & (estaciones.long.between(-120, -70))\n",
    "    estaciones = estaciones[mask]\n",
    "\n",
    "    filename = dir_raw_grl+'estaciones'\n",
    "\n",
    "    estaciones.to_csv (r''+filename+'.csv', index = False, header=True)\n",
    "\n",
    "#Extracts data from cdmx database\n",
    "def merge_aq(city):\n",
    "    \"\"\"Merges the databases from a given city air quality stations into a single csv\n",
    "\n",
    "    Returns:\n",
    "        csv -- csv with all the data from air quality stations\n",
    "    \"\"\"\n",
    "    dir_raw = '../data/raw/'\n",
    "    dir_pcs = '../data/processed/'\n",
    "\n",
    "    years = [2017, 2018, 2019, 2020] #Years to be merged\n",
    "    \n",
    "    all_data = pd.DataFrame()\n",
    "    for year in years:\n",
    "        for i in range(6):\n",
    "            \n",
    "            data = pd.read_excel(dir_raw+city+'/'+str(year)[-2:]+'RAMA/'+str(year)+pollutant(i)+'.xls').replace(-99,np.NaN)\n",
    "            #data = pd.read_csv(dir_raw+city+'/stack/'+str(year)+'.csv').replace(r'^\\s*$',np.nan,regex=True)\n",
    "            data['PARAM'] = pollutant(i)\n",
    "            data = data.set_index(['PARAM','FECHA'])\n",
    "            all_data = all_data.append(data)\n",
    "    \n",
    "    filename = dir_pcs + city + '/' + city + '_' + str(years[0])+'-'+str(years[len(years)-1])\n",
    "    all_data.to_csv (r''+filename+'.csv', index = True, header=True)\n",
    "\n",
    "def res_aqdata(city):\n",
    "    \"\"\"Groups data from air quality stations by date and parameter for every station.\n",
    "\n",
    "    Args:\n",
    "        city (str): city code to by analyzed.\n",
    "    \"\"\"\n",
    "\n",
    "    dir_pcs = '../data/processed/'\n",
    "\n",
    "    years = [2017, 2018, 2019, 2020] #Years to be summarized\n",
    "\n",
    "    res_data = pd.read_csv(dir_pcs +city +'/' + city +'_'+ str(years[0])+'-'+str(years[len(years)-1])+'.csv', index_col = [0,1])\n",
    "    res_data = res_data.groupby(['PARAM','FECHA']).mean()\n",
    "    \n",
    "    filename = dir_pcs +city +'/'+'res_'+ str(years[0])+'-'+str(years[len(years)-1])\n",
    "    res_data.to_csv (r''+filename+'.csv', index = True, header=True)\n",
    "    \n",
    "    \n",
    "def aq_daily_median(city):\n",
    "    \"\"\"Calculates the median by day for a given city and pollutant.\n",
    "\n",
    "    Args:\n",
    "        city (str): city code to calculate median\n",
    "\n",
    "    Returns:\n",
    "        dataframe: returns the dataframe for the date and calculated median.\n",
    "    \"\"\"\n",
    "\n",
    "    dir_pcs = '../data/proccessed/'\n",
    "\n",
    "    years = [2017, 2018, 2019, 2020] #Years to be referenced\n",
    "\n",
    "    aq_median_data = pd.read_csv(dir_pcs +city+'res_'+ str(years[0])+'-'+str(years[len(years)-1])+'.csv', index_col = [0,1]).median(axis=1)\n",
    "    \n",
    "    aq_median_data.to_csv(dir_pcs+city+'median_res_'+ str(years[0])+'-'+str(years[len(years)-1])+'.csv')\n",
    "    \n",
    "    return (aq_median_data)\n",
    "\n",
    "\n",
    "def o3_conc(x):\n",
    "    \"\"\"Calculates the concentration of a pollutant based on air quality index.\n",
    "\n",
    "    Args:\n",
    "        x (int): air quality index of the pollutant\n",
    "\n",
    "    Returns:\n",
    "        float: concentration of the pollutant\n",
    "    \"\"\"\n",
    "    conc = 0\n",
    "    if x <= 50:\n",
    "        conc = ((x-0)*(0.054-0))/(50-0)+0\n",
    "    elif x>50 and x<=100:\n",
    "        conc = ((x-51)*(0.070-0.055))/(100-51)+0.055\n",
    "    elif x>100 and x<=150:\n",
    "        conc = ((x-101)*(0.085-0.071))/(150-101)+0.071\n",
    "    elif x>150 and x<=200:\n",
    "        conc = ((x-151)*(0.105-0.086))/(200-151)+0.086\n",
    "    elif x>200 and x<=300:\n",
    "        conc = ((x-201)*(0.200-0.106))/(300-201)+0.106\n",
    "        \n",
    "    return (conc*1000)\n",
    "\n",
    "def co_conc(x):\n",
    "    \"\"\"Calculates the concentration of a pollutant based on air quality index.\n",
    "\n",
    "    Args:\n",
    "        x (int): air quality index of the pollutant\n",
    "\n",
    "    Returns:\n",
    "        float: concentration of the pollutant\n",
    "    \"\"\"\n",
    "\n",
    "    conc = 0\n",
    "    if x <= 50:\n",
    "        conc = ((x-0)*(4.4-0))/(50-0)+0\n",
    "    elif x>50 and x<=100:\n",
    "        conc = ((x-51)*(9.4-4.5))/(100-51)+4.5\n",
    "    elif x>100 and x<=150:\n",
    "        conc = ((x-101)*(12.4-9.5))/(150-101)+9.5\n",
    "    elif x>150 and x<=200:\n",
    "        conc = ((x-151)*(15.4-12.5))/(200-151)+12.5\n",
    "    elif x>200 and x<=300:\n",
    "        conc = ((x-201)*(30.4-15.5))/(300-201)+15.5\n",
    "    elif x>300 and x<=400:\n",
    "        conc = ((x-301)*(40.4-30.5))/(400-301)+30.5\n",
    "    elif x>400:\n",
    "        conc = ((x-401)*(50.4-40.5))/(500-401)+40.5\n",
    "        \n",
    "    return (conc)\n",
    "\n",
    "def pm10_conc(x):\n",
    "    \"\"\"Calculates the concentration of a pollutant based on air quality index.\n",
    "\n",
    "    Args:\n",
    "        x (int): air quality index of the pollutant\n",
    "\n",
    "    Returns:\n",
    "        float: concentration of the pollutant\n",
    "    \"\"\"\n",
    "\n",
    "    conc = 0\n",
    "    if x <= 50:\n",
    "        conc = ((x-0)*(54-0))/(50-0)+0\n",
    "    elif x>50 and x<=100:\n",
    "        conc = ((x-51)*(154-55))/(100-51)+55\n",
    "    elif x>100 and x<=150:\n",
    "        conc = ((x-101)*(254-155))/(150-101)+155\n",
    "    elif x>150 and x<=200:\n",
    "        conc = ((x-151)*(354-255))/(200-151)+255\n",
    "    elif x>200 and x<=300:\n",
    "        conc = ((x-201)*(424-355))/(300-201)+355\n",
    "    elif x>300 and x<=400:\n",
    "        conc = ((x-301)*(504-425))/(400-301)+425\n",
    "    elif x>400:\n",
    "        conc = ((x-401)*(604-505))/(500-401)+505\n",
    "        \n",
    "    return (conc)\n",
    "        \n",
    "def pm25_conc(x):\n",
    "    \"\"\"Calculates the concentration of a pollutant based on air quality index.\n",
    "\n",
    "    Args:\n",
    "        x (int): air quality index of the pollutant\n",
    "\n",
    "    Returns:\n",
    "        float: concentration of the pollutant\n",
    "    \"\"\"\n",
    "\n",
    "    conc = 0\n",
    "    if x <= 50:\n",
    "        conc = ((x-0)*(12-0))/(50-0)+0\n",
    "    elif x>50 and x<=100:\n",
    "        conc = ((x-51)*(35.4-12.1))/(100-51)+12.1\n",
    "    elif x>100 and x<=150:\n",
    "        conc = ((x-101)*(55.4-35.5))/(150-101)+35.5\n",
    "    elif x>150 and x<=200:\n",
    "        conc = ((x-151)*(150.4-55.5))/(200-151)+55.5\n",
    "    elif x>200 and x<=300:\n",
    "        conc = ((x-201)*(250.4-150.5))/(300-201)+150.5\n",
    "    elif x>300 and x<=400:\n",
    "        conc = ((x-301)*(350.4-250.5))/(400-301)+250.5\n",
    "    elif x>400:\n",
    "        conc = ((x-401)*(500.4-350.5))/(500-401)+350.5\n",
    "        \n",
    "    return (conc*1.0)\n",
    "\n",
    "def so2_conc(x):\n",
    "    \"\"\"Calculates the concentration of a pollutant based on air quality index.\n",
    "\n",
    "    Args:\n",
    "        x (int): air quality index of the pollutant\n",
    "\n",
    "    Returns:\n",
    "        float: concentration of the pollutant\n",
    "    \"\"\"\n",
    "\n",
    "    conc = 0\n",
    "    if x <= 50:\n",
    "        conc = ((x-0)*(35-0))/(50-0)+0\n",
    "    elif x>50 and x<=100:\n",
    "        conc = ((x-51)*(75-36))/(100-51)+36\n",
    "    elif x>100 and x<=150:\n",
    "        conc = ((x-101)*(185-76))/(150-101)+76\n",
    "    elif x>150 and x<=200:\n",
    "        conc = ((x-151)*(304-186))/(200-151)+186\n",
    "    elif x>200 and x<=300:\n",
    "        conc = ((x-201)*(604-305))/(300-201)+305\n",
    "    elif x>300 and x<=400:\n",
    "        conc = ((x-301)*(804-605))/(400-301)+605\n",
    "    elif x>400:\n",
    "        conc = ((x-401)*(1004-805))/(500-401)+805 \n",
    "        \n",
    "    return (conc)\n",
    "\n",
    "def no2_conc(x):\n",
    "    \"\"\"Calculates the concentration of a pollutant based on air quality index.\n",
    "\n",
    "    Args:\n",
    "        x (int): air quality index of the pollutant\n",
    "\n",
    "    Returns:\n",
    "        float: concentration of the pollutant\n",
    "    \"\"\"\n",
    "\n",
    "    conc = 0\n",
    "    if x <= 50:\n",
    "        conc = ((x-0)*(53-0))/(50-0)+0\n",
    "    elif x>50 and x<=100:\n",
    "        conc = ((x-51)*(100-54))/(100-51)+54\n",
    "    elif x>100 and x<=150:\n",
    "        conc = ((x-101)*(360-101))/(150-101)+101\n",
    "    elif x>150 and x<=200:\n",
    "        conc = ((x-151)*(649-361))/(200-151)+361\n",
    "    elif x>200 and x<=300:\n",
    "        conc = ((x-201)*(1249-650))/(300-201)+650\n",
    "    elif x>300 and x<=400:\n",
    "        conc = ((x-301)*(1649-1250))/(400-301)+1250\n",
    "    elif x>400:\n",
    "        conc = ((x-401)*(2049-1650))/(500-401)+1650\n",
    "        \n",
    "    return (conc*1.0)\n",
    "    \n",
    "#Extracts data from aqip database\n",
    "def aqip_data():\n",
    "    \"\"\"Function that extracts data for mexican city from the Air Quality Index Project database.\n",
    "\n",
    "    \"\"\"\n",
    "    dir_raw_aqip = '../data/raw/AirQualityIndexProject/world_data/'\n",
    "    dir_pcs_aqip = '../data/processed/aqip/'\n",
    "    \n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    for file in os.listdir(dir_raw_aqip):\n",
    "\n",
    "        filename = dir_raw_aqip + file\n",
    "        \n",
    "        data_aqip = pd.DataFrame()\n",
    "        \n",
    "        data_aqip = pd.read_csv(filename, skiprows=4)\n",
    "        \n",
    "        data_aqip['Specie'] = data_aqip['Specie'].str.upper()\n",
    "        \n",
    "        data_aqip = data_aqip.set_index(['Specie'])\n",
    "        \n",
    "        data_aqip = data_aqip[data_aqip['Country']=='MX'].drop(['Country'], axis=1)\n",
    "        \n",
    "        all_data = all_data.append(data_aqip)\n",
    "        \n",
    "    #Condition that selects pollutant\n",
    "    cond = [all_data.index == 'O3', all_data.index == 'CO', all_data.index == 'PM10', \n",
    "           all_data.index == 'PM25', all_data.index == 'NO2', all_data.index == 'SO2']\n",
    "    \n",
    "    #Choice that dictates what happends for each case\n",
    "    choice = [all_data['median'].apply(o3_conc), all_data['median'].apply(co_conc), \n",
    "             all_data['median'].apply(pm10_conc), all_data['median'].apply(pm25_conc),\n",
    "             all_data['median'].apply(no2_conc), all_data['median'].apply(so2_conc)]\n",
    "    \n",
    "    #Calculates a new column with the data converted from \n",
    "    #air quality index to concentration by pollutant\n",
    "\n",
    "    all_data['c_median'] = np.select(cond, choice)\n",
    "    \n",
    "    all_data = all_data.reset_index().set_index(['City','Specie','Date']).drop_duplicates()\n",
    "\n",
    "    all_data.to_csv(dir_pcs_aqip +'MX_2015_2020.csv')\n",
    "    \n",
    "    \n",
    "def gdl_data ():\n",
    "    dir_gdl = '../data/raw/gdl/'\n",
    "    \n",
    "    est_dict = {'√ÅGUILAS':'AGU', 'ATEMAJAC':'ATM', 'CENTRO':'CEN', \n",
    "                'LAS PINTAS':'PIN', 'LOMA DORADA':'LDO', 'MIRAVALLE':'MIR', 'OBLATOS':'OBL', \n",
    "                'SANTA FE':'SFE', 'TLAQUEPAQUE':'TLA', 'VALLARTA':'VAL'}\n",
    "    \n",
    "    for file in os.listdir(dir_gdl):\n",
    "\n",
    "        f_check = os.path.join(dir_gdl,file)\n",
    "\n",
    "        if os.path.isfile(f_check):\n",
    "\n",
    "            xls = xlrd.open_workbook(r''+dir_gdl+file, on_demand=True)\n",
    "            sheets = xls.sheet_names()\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        year = file[6:10]\n",
    "        \n",
    "        print (year)\n",
    "        \n",
    "        df = pd.DataFrame(columns=['O3','CO','PM10','SO2','NO2'])\n",
    "\n",
    "        df['FECHA'] = pd.date_range(start = pd.Timestamp(year), \n",
    "                                   end = pd.Timestamp(year) + pd.tseries.offsets.YearEnd(0),\n",
    "                                   freq = 'D')\n",
    "\n",
    "        df = df.set_index('FECHA')\n",
    "        df = df.stack(dropna=False)\n",
    "        all_data = pd.DataFrame(df)\n",
    "        all_data = all_data.rename_axis(index=['FECHA','PARAM'])\n",
    "        all_data = all_data.drop(columns=[0])\n",
    "        \n",
    "        #print(all_data)\n",
    "\n",
    "        for s in sheets:\n",
    "\n",
    "            gdl_data = pd.read_excel(dir_gdl+file, sheet_name = s).rename(columns={'Fecha':'FECHA',\n",
    "                                                                                   'Hora':'HORA'}).replace(r'^\\s*$', \n",
    "                                                                                                           np.nan, \n",
    "                                                                                                           regex=True)\n",
    "            gdl_data.columns = [col.strip() for col in gdl_data.columns]\n",
    "            \n",
    "            gdl_data = gdl_data[['FECHA','O3','NO2','SO2','PM10','CO']]\n",
    "\n",
    "            gdl_data['FECHA'] = gdl_data['FECHA'].dt.date\n",
    "\n",
    "            gdl_stack = pd.DataFrame(gdl_data.set_index(['FECHA']).stack([0]))\n",
    "\n",
    "            gdl_stack = gdl_stack.reset_index().rename(columns={'level_1':'PARAM',\n",
    "                                                                0:est_dict[s.strip(' ').upper()]})\n",
    "            \n",
    "            gdl_stack['FECHA'] = pd.to_datetime(gdl_stack['FECHA'])\n",
    "            \n",
    "            gdl_stack = gdl_stack[gdl_stack['FECHA'].dt.year==int(file[6:10])]\n",
    "\n",
    "            gdl_stack[est_dict[s.strip(' ').upper()]] = pd.to_numeric(gdl_stack[est_dict[s.strip(' ').upper()]], errors='coerce')\n",
    "\n",
    "            gdl_stack = gdl_stack.groupby(['FECHA','PARAM']).mean()\n",
    "\n",
    "            all_data = pd.merge(all_data, gdl_stack, how='outer',left_index=True, right_index=True)\n",
    "            \n",
    "        \n",
    "        #print (all_data)\n",
    "        all_data.to_csv(dir_gdl+'stack/'+file[6:10]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_aqdata('cdmx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('geo_env': conda)",
   "language": "python",
   "name": "python38364bitgeoenvconda2cb6af09078d46c89f7c036ca6304ba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
